{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/Users/nabilahmed/RL-book/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Sequence, Tuple, List\n",
    "import numpy as np\n",
    "import random\n",
    "from scipy.stats import norm\n",
    "import pandas as pd\n",
    "from rl.function_approx import DNNApprox, LinearFunctionApprox, \\\n",
    "    FunctionApprox, DNNSpec, AdamGradient, Weights\n",
    "from random import randrange\n",
    "from numpy.polynomial.laguerre import lagval\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "from random import randrange\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create LSPI Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainingDataType = Tuple[float, float, float, float, float, float, \n",
    "                         float, float, float, float, float, float]\n",
    "\n",
    "def fitted_lspi_put_option(\n",
    "    feature_vals: np.ndarray,\n",
    "    next_feature_vals: np.ndarray,\n",
    "    training_iters: int,\n",
    "    num_intervals: int\n",
    ") -> LinearFunctionApprox:\n",
    "\n",
    "    epsilon: float = 1e-3\n",
    "    # Index(['Interval', 'CumulativePlayerPointsInterval', 'Home', 'TeamRest',\n",
    "    #       'OpponentTeamRest', 'CumulativeTeamPointsInterval',\n",
    "    #       'CumulativeOpponentPointsInterval', 'ScoreMarginInterval',\n",
    "    #       'ScoreMarginxTimeRemainingInterval',\n",
    "    #       'ScoreMarginxTimeRemaining2Interval', 'RollingAvgPlayerPoints',\n",
    "    #       'RollingAverageOpposingTeamAllowedPoints', 'RollingAverageTeamPoints']\n",
    "    exer: np.ndarray = np.array([max(row[1] - row[10] * (row[0] / num_intervals), 0) for row in feature_vals])\n",
    "    non_terminal: np.ndarray = np.array([row[0] < num_intervals for row in feature_vals])\n",
    "\n",
    "    features = list(lambda x: x[i] for i in range(13))\n",
    "\n",
    "    gamma: float = 1.0\n",
    "    num_features: int = len(features) # will be hardcoded based on Spencer's code\n",
    "\n",
    "    wts: np.ndarray = np.zeros(num_features)\n",
    "    for _ in range(training_iters):\n",
    "        a_inv: np.ndarray = np.eye(num_features) / epsilon\n",
    "        b_vec: np.ndarray = np.zeros(num_features)\n",
    "        cont: np.ndarray = np.dot(next_feature_vals, wts)\n",
    "        cont_cond: np.ndarray = non_terminal * (cont > exer)\n",
    "        for i in range(len(feature_vals)):\n",
    "            phi1: np.ndarray = feature_vals[i]\n",
    "            phi2: np.ndarray = phi1 - \\\n",
    "                cont_cond[i] * gamma * next_feature_vals[i]\n",
    "            temp: np.ndarray = a_inv.T.dot(phi2)\n",
    "            a_inv -= np.outer(a_inv.dot(phi1), temp) / (1 + phi1.dot(temp))\n",
    "            b_vec += phi1 * (1 - cont_cond[i]) * exer[i] * gamma\n",
    "        wts = a_inv.dot(b_vec)\n",
    "\n",
    "    return LinearFunctionApprox.create(\n",
    "        feature_functions=features,\n",
    "        weights=Weights.create(wts)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(100)\n",
    "np.random.seed(100)\n",
    "\n",
    "# read in data from nba csv file\n",
    "df = pd.read_csv('NBA_PBP_2018-19_processed_points.csv')\n",
    "# sort by Player, GameId, and Interval\n",
    "df = df.sort_values(by=['Player', 'GameId', 'Interval'], ascending=True)\n",
    "df = df[df['RollingAvgPlayerPoints'] > 15]\n",
    "names = df['Player']\n",
    "# drop date, player, gameid\n",
    "df = df[['Interval', 'CumulativePlayerPointsInterval', 'Home', 'TeamRest',\n",
    "        'OpponentTeamRest', 'CumulativeTeamPointsInterval',\n",
    "        'CumulativeOpponentPointsInterval', 'ScoreMarginInterval',\n",
    "        'ScoreMarginxTimeRemainingInterval',\n",
    "        'ScoreMarginxTimeRemaining2Interval', 'RollingAvgPlayerPoints',\n",
    "        'RollingAverageOpposingTeamAllowedPoints', 'RollingAverageTeamPoints']]\n",
    "# drop rows with missing values\n",
    "df = df.dropna()\n",
    "# convert to numpy array\n",
    "feature_vals = df.to_numpy()\n",
    "next_features = copy.deepcopy(feature_vals)\n",
    "# move first row to last row\n",
    "next_feature_vals = np.roll(next_features, -1, axis=0)\n",
    "\n",
    "flspi: LinearFunctionApprox[Tuple[float, float]] = fitted_lspi_put_option(\n",
    "    feature_vals=feature_vals,\n",
    "    next_feature_vals=next_feature_vals,\n",
    "    training_iters=100,\n",
    "    num_intervals=4,\n",
    ")\n",
    "names = names.to_numpy()\n",
    "\n",
    "print(\"Fitted LSPI Model\")\n",
    "\n",
    "# fdql: DNNApprox[Tuple[float, float]] = fitted_dql_put_option(\n",
    "#     expiry=expiry_val,\n",
    "#     num_steps=num_steps_dql,\n",
    "#     num_paths=num_training_paths_dql,\n",
    "#     spot_price=spot_price_val,\n",
    "#     spot_price_frac=spot_price_frac_dql,\n",
    "#     rate=rate_val,\n",
    "#     vol=vol_val,\n",
    "#     strike=strike_val,\n",
    "#     training_iters=training_iters_dql\n",
    "# )\n",
    "\n",
    "# Index(['Interval', 'CumulativePlayerPointsInterval', 'Home', 'TeamRest',\n",
    "#       'OpponentTeamRest', 'CumulativeTeamPointsInterval',\n",
    "#       'CumulativeOpponentPointsInterval', 'ScoreMarginInterval',\n",
    "#       'ScoreMarginxTimeRemainingInterval',\n",
    "#       'ScoreMarginxTimeRemaining2Interval', 'RollingAvgPlayerPoints',\n",
    "#       'RollingAverageOpposingTeamAllowedPoints', 'RollingAverageTeamPoints']\n",
    "res = np.matmul(feature_vals, flspi.weights.weights)\n",
    "#res = pd.DataFrame(res)\n",
    "df['Player'] = names\n",
    "df['res'] = res\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create DQL Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN_model(nn.Module):\n",
    "    def __init__(self, num_features: int):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(num_features, 15)\n",
    "        self.layer2 = nn.Linear(15, 15)\n",
    "        self.layer3 = nn.Linear(15, 1)\n",
    "\n",
    "        # Initialize the linear layers\n",
    "        nn.init.uniform_(self.layer1.weight, a = -0.1, b = 0.1)\n",
    "        nn.init.uniform_(self.layer2.weight, a = -0.1, b = 0.1)\n",
    "        nn.init.uniform_(self.layer3.weight, a = -0.1, b = 0.1)\n",
    "        nn.init.zeros_(self.layer1.bias)\n",
    "        nn.init.zeros_(self.layer2.bias)\n",
    "        nn.init.zeros_(self.layer3.bias)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x2 = F.softplus(self.layer1(x))\n",
    "        x3 = F.softplus(self.layer2(x2))\n",
    "        return self.layer3(x3)\n",
    "    \n",
    "    def forward_in_batches(self, x):\n",
    "        with torch.no_grad():\n",
    "            batch_size = 100\n",
    "            num_batches = int(np.ceil(x.shape[0] / batch_size))\n",
    "            y = []\n",
    "            for i in range(num_batches):\n",
    "                y.append(self.forward(x[i * batch_size: min((i + 1) * batch_size, x.shape[0])]))\n",
    "            return torch.cat(y)\n",
    "\n",
    "def fitted_dql_put_option(\n",
    "    feature_vals: np.ndarray,\n",
    "    next_feature_vals: np.ndarray,\n",
    "    training_iters: int,\n",
    "    num_intervals: int\n",
    ") -> torch.nn.Module:\n",
    "    \n",
    "    model = DQN_model(num_features=13)\n",
    "    features_vals = torch.tensor(feature_vals, dtype=torch.float)\n",
    "    next_feature_vals = torch.tensor(next_feature_vals, dtype=torch.float)\n",
    "\n",
    "    exer: np.ndarray = np.array([max(row[1] - row[10] * (row[0] / num_intervals), 0) for row in feature_vals])\n",
    "    non_terminal: np.ndarray = np.array([row[0] < num_intervals for row in feature_vals])\n",
    "\n",
    "    alpha = 0.003\n",
    "\n",
    "    for _ in tqdm(range(training_iters), desc=\"Epochs\"):\n",
    "        i = randrange(len(feature_vals))\n",
    "        q_score = model(features_vals[i])\n",
    "        q_score_next = model(next_feature_vals[i])\n",
    "        grad = torch.autograd.grad(q_score, model.parameters())\n",
    "        with torch.no_grad():\n",
    "            if non_terminal[i]:\n",
    "                for param, g in zip(model.parameters(), grad):\n",
    "                    param.add_(alpha * (max(exer[i], q_score_next)-q_score) * g)\n",
    "            else:\n",
    "                for param, g in zip(model.parameters(), grad):\n",
    "                    param.add_(alpha * (exer[i]-q_score) * g)\n",
    "                    \n",
    "        alpha = max(alpha * 0.999, .00001) # decay learning rate\n",
    "        model.zero_grad()  # reset gradients\n",
    "    \n",
    "    return model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 500000/500000 [01:24<00:00, 5895.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted DQL Model\n",
      "done\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "random.seed(100)\n",
    "np.random.seed(100)\n",
    "\n",
    "# read in data from nba csv file\n",
    "df = pd.read_csv('NBA_PBP_2018-19_processed_points.csv')\n",
    "# sort by Player, GameId, and Interval\n",
    "df = df.sort_values(by=['Player', 'GameId', 'Interval'], ascending=True)\n",
    "df = df[df['RollingAvgPlayerPoints'] > 15]\n",
    "names = df['Player']\n",
    "# drop date, player, gameid\n",
    "df = df[['Interval', 'CumulativePlayerPointsInterval', 'Home', 'TeamRest',\n",
    "        'OpponentTeamRest', 'CumulativeTeamPointsInterval',\n",
    "        'CumulativeOpponentPointsInterval', 'ScoreMarginInterval',\n",
    "        'ScoreMarginxTimeRemainingInterval',\n",
    "        'ScoreMarginxTimeRemaining2Interval', 'RollingAvgPlayerPoints',\n",
    "        'RollingAverageOpposingTeamAllowedPoints', 'RollingAverageTeamPoints']]\n",
    "# drop rows with missing values\n",
    "df = df.dropna()\n",
    "# convert to numpy array\n",
    "feature_vals = df.to_numpy()\n",
    "\n",
    "# Standardize the columns of the data except for those used in exer\n",
    "means_vec = np.mean(feature_vals, axis=0)\n",
    "std_vec = np.std(feature_vals, axis=0)\n",
    "means_vec[0] = 0\n",
    "std_vec[0] = 1\n",
    "means_vec[1] = 0\n",
    "std_vec[1] = 1\n",
    "means_vec[10] = 0\n",
    "std_vec[10] = 1\n",
    "feature_vals = (feature_vals - means_vec) / std_vec\n",
    "next_features = copy.deepcopy(feature_vals)\n",
    "# move first row to last row\n",
    "next_feature_vals = np.roll(next_features, -1, axis=0)\n",
    "\n",
    "fldq: torch.nn.Module = fitted_dql_put_option(\n",
    "    feature_vals=feature_vals,\n",
    "    next_feature_vals=next_feature_vals,\n",
    "    training_iters=500000,\n",
    "    num_intervals=4,\n",
    ")\n",
    "names = names.to_numpy()\n",
    "\n",
    "print(\"Fitted DQL Model\")\n",
    "\n",
    "\n",
    "# Index(['Interval', 'CumulativePlayerPointsInterval', 'Home', 'TeamRest',\n",
    "#       'OpponentTeamRest', 'CumulativeTeamPointsInterval',\n",
    "#       'CumulativeOpponentPointsInterval', 'ScoreMarginInterval',\n",
    "#       'ScoreMarginxTimeRemainingInterval',\n",
    "#       'ScoreMarginxTimeRemaining2Interval', 'RollingAvgPlayerPoints',\n",
    "#       'RollingAverageOpposingTeamAllowedPoints', 'RollingAverageTeamPoints']\n",
    "#res = np.matmul(feature_vals, flspi.weights.weights)\n",
    "res = fldq.forward_in_batches(torch.tensor(feature_vals, dtype=torch.float))\n",
    "# convert res to numpy array from torch tensor\n",
    "res = res.numpy()\n",
    "# make a histogram using res\n",
    "plt.hist(res, bins=100)\n",
    "\n",
    "df['Player'] = names\n",
    "df['res'] = res\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('dqn_nba_output.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
